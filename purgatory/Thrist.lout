@SysInclude { report }
@SysInclude { fig }
@SysInclude { diag }
@SysInclude { tbl }
@SysInclude { graph }
@SysInclude { eq }
@Include { haskellx }
@Database @FontDef {"db/lm"}
@Database @Reference {"db/acmrefs"}
@Database @Reference {"db/refs"}

def @TargetForExtract right output {}

def @IgnoreForOutput right stuff {}

def @Prompt left input right output { { Helvetica Base -1p } @Font { prompt> @Haskell { input } @PP { output } } }
def @Omega { {@I {@Sym Omega}}mega }
def @Cat { { Helvetica Base -1p } @Font Cat }
def @CLang { { Helvetica Base -1p } @Font C }

@Report
  @CoverSheet { No }
  @ColumnNumber { 2 }
  @InitialFont { LMnine Base 9p }
  @DateLine { Yes }
  @Title { Thrists: Dominoes of Data }
  @Author { Gabor Greif }
  @Institution { "gabor@mac.com" }
#  @SectionHeadingFont { Helvetica Bold }
  @AbstractDisplay { Yes }
# @AbstractFormat { @Centre @Title @DP @Body }
@Abstract {
We develop a novel list-like datastructure (which we name @Haskell {Thrist}),
that is able to capture the typing rule of function composition.
Indeed, we show that when @Haskell {Thrist} is parameterized with the function
type constructor @Haskell {(->)} an interpretation function can be provided
which completely emulates the classical function composition @Haskell {(.)}.
Additionally we can perform pattern matching on our @Haskell {Thrist} elements, thus
obtaining the ability to do analysis on them. On the practical side
we develop three new two-parameter GADTs for inclusion into {@Haskell {Thrist}}s.
The first, when accompanied by an appropriate interpreter, directly model the semantics
of the @Cat language, while the second caters for a new type of parser combinator libraries.
In our third example we demonstrate the use of {@Haskell {Thrist}}s in state machines.
The @Haskell {Thrist} approach of exposing the intermediate types where the
elements are joined together shows its potential especially in the ability to
stage the interpreter in a type-safe way and only allows for type correct
transformations.
}
//

@Section
@Title { Structure of the Paper }
@Begin
@PP
In the following section we motivate our subsequent introduction of @Haskell {Thrist}
with well known examples. The third section is devoted to the development of
three practial applications of @Haskell {Thrist}s. Next we present some less useful
but entertaining uses. Section five examines other work, while section six concludes,
pointing out open problems and showing up possible future directions.
@End @Section

@Section
@Title { Introduction }
@Begin
@PP
We are well acquainted with data structures that are parameterized over
data types, as they are a bread-and-butter tool for functional programmers.
For example the @Haskell {List} datatype could be introduced in the
Haskell-like language @Omega @Cite { $sheard07.omega }
with the following definition:
@PP
@TargetForExtract "check/List"
@ID @Haskell @Begin
data List :: * ~> * where
  Nil :: List a
  Cons :: a -> List a -> List a
@End @Haskell
@PP
We deliberately avoid the traditional syntax of defining the @Haskell {List} datatype,
and use a @I {GADT-style} definition{@FootNote {in a @I {generalized algebraic datatype}
the data constructor is allowed to define a more specific type than the datatype itself }},
because we want to build on this fundament later.
It is enough to say that @Haskell {List} does not impose any constraints on the
contained datatype whatsoever:
@LD {
{Cons 42 (Cons 33 (Cons 5 Nil))} @Prompt
  { Cons 42 (Cons 33 (Cons 5 Nil)) :: List Int }
}

Departing from single-parameter datatypes we focus on two-parameter
datatypes from now on. These are more interesting for our purposes,
because the two parameters can be put in relation to each other.
The most prominent member of this class of types is the arrow type:

@LD {
{ :k (->) } @Prompt
  { (->) :: *0 "~>" *0 "~>" *0 }
}

Fully saturated, @Haskell {a -> b} signifies the type of all functions that take elements of @Haskell {a} to
elements of @Haskell {b}. Again, @Haskell {a} and @Haskell {b} can be any type, concrete ones will do just like
universally qualified ones:
@LD {
{id} @Prompt
  {<fn> : forall a.a -> a}
}
@RLD {
{ord} @Prompt
  {<primfun ord> : Char -> Int}
}
@LP
Now, functions are a bit more interesting than @Haskell {List}s above, for they can be composed!
Interestingly, composition (written as @Haskell {(.)}) is again a function:
@LD {
{(.)} @Prompt
  {<fn> : forall a b c.(a -> b) -> (c -> a) -> c -> b}
}
This function signature has several interpretations, but the most common one tells us that
the composition function @Haskell {(.)} takes a function with type @Haskell {a -> b} as its first argument, then
a function with type @Haskell {c -> a} as its second argument, and returns a function of type @Haskell {c -> b}.
Again, @Haskell {a}, @Haskell {b} and @Haskell {c} can be arbitrarily specialized or be left universal.
We can play with our new toy in the following way:

@LD {
{ let locase = chr . ("\\"x -> x + 32) . ord } @Prompt
{ locase }
}
@RLD {
{  locase 'G' } @Prompt
{  'g' : Char }
}
@LP
The type of the composition function constrains the types of its arguments in
a nontrivial way: the range of the second funtion must match with the domain
of the first (universally qualified types will always match,
while monotypes must be equal). Violating this rule gives a type error:

@LD {
{ ord . ord } @Prompt
{
In the expression: ord
the result type: Char -> Int
was not what was expected: a -> Char
}
}

This crucial property of the composition function will guide our explorations in this
paper.

@BeginSubSections

@SubSection
@Title { Generalizing Function Composition }
@Begin
@PP
While function composition seems to be a cute artifact of mathematics, (where
nevertheless all computable functions can be derived from), this is no reason
for us to stop at this point! First, we observe that function composition is a one-way
street: once two functions are composed, they amalgamate beyond recognition.
There is no way (inside our system) to take them apart again. This is very much
resembling the addition, where @Haskell { (23 + 19) } gives @Haskell {42} and this result has completely
lost all memories of the fact how it was obtained. But can we create a datastructure
that has all properties of function composition, without being amnesiac?
@PP
Indeed we can, and the rest of this section shall explain how.
@PP
Our crucial observation from the introduction was that the types at the ends of the function
arrows must thread up, intuitively @FootNote { we reconcile the discrepancy between
the function arrow's @Haskell {(->)} direction and the customary
composition @Haskell {g . f} by considering a modified @I {reverse composition} }:

@ID { @Haskell {a ->} @Box @Haskell {b (.) b} @Haskell {-> c} @Sym equivalence @Haskell {a -> c} }

We also observe that the intermediate types do not show up in the end result's type.

Let's simulate these rules as a datatype:

@TargetForExtract "check/Thrist1"
@ID @Haskell @Begin
data Thrist :: * ~> * ~> * where
  Nil :: Thrist a a
  Cons :: (a, b) -> Thrist b c -> Thrist a c
@End @Haskell

The alert reader will have noticed that we have defined a proper GADT,
since e.g. the @Haskell {Nil} constructor is only inhabiting the @I diagonal
of the @I {two-dimensional} parameter space.
@PP
We can now duplicate the @I feeling of function composition:

@Haskell operators {Base} { Cons ('g', 103) $ Cons (103, 71) $ Cons (71, 'G') Nil }

Also we have obtained a datatype that is not amnesiac, i.e. it can be
torn apart at any place by pattern matching, though we have to pay
the price that the intermediate types are a bit hard to deal with
(we shall revisit this issue later).
@PP
It appears that we have reached our goal, we can form list-like data where the intermediate
types thread up, we are happy and name our new toy @Haskell {Thrist}, a portmanteau of thread and list.
@PP
Our joy, however, quickly fades away when we compare our thrist with the composition function.
How can some data of type @Haskell {Thrist a b} be interpreted as an arrow type @Haskell {a -> b}?
If we fail to provide this embedding, we cannot consider thrists being a generalisation of
function composition.
@PP
Not everything is lost, however. Close scrutiny reveals that our usage of
@Haskell {(,)}{@FootNote { pronounced ''pair``}}
is the culprit. If we could liberate ourselves from this
premature decision, we could gain back our hope.
@End @SubSection

@SubSection
  @Title { The Improved Thrist }
  @Tag {intro.compose}
@Begin
@PP
We try all over again, this time abstracting away the pair into an additional parameter:

@TargetForExtract "check/Thrist"
@LD @Haskell @Begin
data Thrist :: (* ~> * ~> *) ~> * ~> * ~> * where
  Nil :: Thrist p a a
  Cons :: p a b -> Thrist p b c -> Thrist p a c
 deriving List(l)
@End @Haskell

All that remains of the pair is the bitter aftertaste
and the letter @Haskell {p} in the definition of @Haskell {Thrist}.
@PP
It looks like we are getting closer now:
@LD {
{ Cons chr (Cons ("\\"x -> x + 32) (Cons ord Nil)) } @Prompt
{ ... : Thrist (->) Char Char }
}
We have created an @I {arrow thrist}!

Immediately we can retry our previous attempt:
@LD {
{ Cons ('g', 103) (Cons (103, 71) (Cons (71, 'G') Nil)) } @Prompt
{  ... : Thrist (,) Char Char }
}
The @I {pair thrist} that caused us some headache before!
@PP
We shall explore some other interesting but sometimes futile
thrists later in the discussion. But now let's put the last missing
piece in place to show that an arrow thrist is strictly more general
than function composition. Here comes the @Haskell {runArrowThrist} function:

@LD @Haskell @Begin
runArrowThrist :: Thrist (->) b c -> c -> b
runArrowThrist Nil b = b
runArrowThrist (Cons f r) a = runThrist r (f a)
@End @Haskell


This function now confirms the vague intuition that @Haskell {Nil} plays the r{@Char ocircumflex}le of
the neutral element of the arrow thrist, just like the identity function
plays the r{@Char ocircumflex}le of the neutral element in the monoid of composed functions.
We shall encounter this recurring fact as we proceed to our examples' implementations.
@LP The definition of @Haskell { runArrowThrist } on a @Haskell { Cons } constructor
deserves some attention. We have not yet explicitly mentioned it, but range of
the function @Haskell { f } is existentially qualified, because it does not
appear in the final result of @Haskell { Cons }. This implies a minor complication
when pattern matching: the {@I head} component{@FootNote {or for symmetry reasons the {@I tail} too} }
of a @Haskell { Cons } cannot be
passed to non-local functions, because the existential type would escape.
@PP
Looking back at our progress so far, the analogy of thrists with the game of
dominoes @Cite {$wikipedia.dominoes} could spring into our minds:
@LP Dominoes are only laid out in a valid configuration, when the stones sharing a common
edge possess the same number of dots next to this edge. Our @Haskell {Nil}
corresponds to an empty board, and @Haskell { Cons } joins two stones with
a common edge. A simple, but important difference to our thrists is that the
dominoes' face numbers do not correspond to the contained @I {value}, but to the
@I type of the contained value: we are playing dominoes at the type level.

@End @SubSection

@EndSubSections

@End @Section

@Section
@Title { Three Practical @Haskell { Thrist }s }
@Begin
@PP

Now that we have defined the @Haskell { Thrist } datatype and gave a sufficiently
generic interface to cover nontrivial cases, time has come to look for
real-world applications. Specifically we shall describe a combinator
library for creating ASTs of @Cat, a statically typed "stack-oriented"
language @Cite { $cat.intro }. As a second application we shall draft a parser
combinator library that admits various implementation strategies. We shall also
sketch the use of thrists in transition arrows of state machines to obtain certain
correctness guarantees, and finally show some curious examples that may even have
some practical value.

@BeginSubSections

@SubSection
@Title { Application one: the @Cat Thrist }
@Begin
@PP
Like all stack-oriented languages, @Cat employs a simple idiom of
computation. A rich set of primitives are available for pushing
values on a stack, permuting them and popping them off. Logical
and arithmetic primitives consume portions of the top of the stack
(TOS) and deposit results in their place. Procedures can be defined
as a succession of primitive invocations and procedure calls.
The semantics of procedure calls is defined as the insertion of the
called procedure's contents to the point of the invocation.
@PP
Let's begin with the definition of the @Haskell {Cat} data-stucture, that will
serve as the first parameter to @Haskell {Thrist}. Clearly it should be
parametrized with two types. Naturally we choose the
first type parameter to describe the shape of the stack before
and the second parameter after the @Haskell {Cat} primitive has been
executed.

@TargetForExtract "check/Cat"
@ID @Haskell @Begin
data Cat :: * ~> * ~> * where
  Push :: a -> Cat opaque (a, opaque)
  Pop :: Cat (a, opaque) opaque
  Dup :: Cat (a, opaque) (a, (a, opaque))
  Add :: Cat (Int, (Int, opaque)) (Int, opaque)
@End @Haskell

@BeginSubSubSections

@SubSubSection
@Title { First Explorations }
@Begin
@PP
We shall extend our @Haskell {Cat} with new primitives as the need arises, but
for now we have enough to perform some experiments.
We have chosen the tuple datatype to represent stack shapes,
but we are free to pick any other sequence-like datatype that
is able to record the type of each element.
The @Haskell {Cat} datatype is defined as a GADT, which will guarantee
that only sematically sound programs can be expressed as a
@Haskell {Thrist Cat}. We can begin our explorations immediately:
@LD {
{ Cons (Push 19) $ Cons (Push 23) $ Cons Add $ Cons Pop Nil } @Prompt
{ Cons (Push 19) (Cons (Push 23) (Add (Cons Pop (Cons Add (Cons Pop Nil)))) :: Thrist Cat a a }
}
The data we built up can be a representation of a @Cat program that
pushes 19 and then 23 on the stack, adds them, keeping only the
result 42 on the stack, and then pops this result off. The inferred type
tells us that there is no net change in the stack's shape.

@End @SubSubSection


@SubSubSection
@Title { Making Use of {@Omega}'s Features }
@Begin
@PP
We shall from now on make use of a feature of the @Omega language
to define custom syntax for datatypes. Our aim is to hide the
@Haskell {Thrist} constructors @Haskell { Cons } and @Haskell { Nil } behind a more intuitive fa{@Char ccedilla}ade.
In the rest of this paper we shall write the above expression as
@LD {
{ [Push 19, Push 23, Add, Pop]l } @Prompt
{ [Push 19, Push 23, Add, Pop]l :: Thrist Cat a a }
}
@Omega's parser and printer perform the conversion to
the internal form when the list-like brackets @Haskell {[]} followed
by the letter ''l`` are encountered.
@PP
We can now continue using this terser syntax:
@LD {
{ [Pop, Pop]l } @Prompt
{ [Pop, Pop]l :: Thrist Cat (a, (b, c)) c }
}
The inferred type reflects the function of this @Cat fragment,
namely starting out with a stack that has at least two elements
pushed, we end up with those two values removed.
@LP There are invalid @Cat programs, for example addition of two
characters:
@LD {
{ [Push 'a', Dup, Add]l } @Prompt
{ the result type: ... was not what was expected: ... }
}
The GADT-based type inference fails, because @Haskell { Add }
expects two integers on the stack, but there are two @Haskell { Char }s available instead.
@End @SubSubSection

@SubSubSection
@Title { Interpreter }
@Begin
@PP
Now it is time to build an interpreter for @Haskell {Thrist Cat}, and
thus define its big-step semantics:
@LD @Haskell @Begin
interpret' :: Thrist Cat a b -> a -> b
interpret' []l st = st
interpret' [Push x; rest]l st = interpret' rest (x, st)
interpret' [Pop; rest]l (a, st) = interpret' rest st
interpret' [Dup; rest]l (a, st) = interpret' rest (a, a, st)
interpret' [Add; rest]l (a, b, st) = interpret' rest (a + b, st)
@End @Haskell
It works:

@LD {
{ interpret' [Push 19, Push 23, Add]l () } @Prompt
{ (42, ()) :: (Int, ()) }
}

With this basic functionality in place, we get bolder and define
a primitive with side effect:

@ID @Haskell {
data Cat :: * ~> * ~> * where
  Print :: Cat (a, opaque) opaque
  ...
}

To interpret the @Haskell {Print} primitive we have to restructure
our @Haskell {interpret'} function to wrap the stack into the @Haskell {IO} monad:

@ID @Haskell operators {Base} {
interpret' :: Thrist Cat a b -> IO a -> IO b
interpret' [Print; rest]l st = do
        (a, st') <- st
        putStr $ show a
        interpret' rest st'
  where monad ioM
}
In this function @Haskell { ioM } is globally bound to a value of type @Haskell { Monad IO }
containing the monadic @Haskell { return } and @Haskell { bind } functions
for the { @I do-notation }'s perusal{ @FootNote { @Omega's (current) lack of @I { type classes }
necessitates the explicit passing of @Haskell { Monad :: (* ~> *) ~> * } values (dictionaries)} }.
In similar spirit we have to rewrite the other cases too:

@ID @Haskell operators {Base} @Begin
interpret' [Pop; rest]l st = do
        (a, st') <- st
        interpret' rest $ return st'
  where monad ioM

interpret' [Push x; rest]l st = do
        interpret' rest $ return (x, st)
  where monad ioM

interpret' [Dup; rest]l st = do
        (a, st') <- st
        interpret' rest $ return (a, a, st')
  where monad ioM

interpret' [Add; rest]l st = do
        (a, b, st') <- st
        interpret' rest $ return (a + b, st')
  where monad ioM
@End @Haskell

Trying out this monadic interpreter gives us:
@LD {
{ interpret' [Push 21, Dup, Add, Print]l (returnIO ()) } @Prompt
{ Executing IO action
@LP 42
@PP () :: IO () }
}

It is a reasonable restriction to @Cat programs that they can
be started with any stack shape and they finish with the same
stack unchanged. We can ensure this property by writing
a top-level interpreter function for @Cat programs using
@I {rank-2 polymorphism}:

@ID @Haskell operators {Base} @Begin
interpret :: (forall a. Thrist Cat a a) -> IO ()
interpret program = interpret' program $ returnIO ()
@End @Haskell

Obviously this @Haskell {interpret} function is only called for side-effects.
@End @SubSubSection

@SubSubSection
@Title { Extending the Primitives }
@Begin
@PP

Above we have defined an arithmetic primitive in @Cat, namely @Haskell { Add }. While possible,
it is not desired to define all (which is potentially a lot) primitives this
way, with their own typing rules, and own clause in the interpreter. Also,
this approach does preclude a very useful notion, called @I { partial application }. In this
example, @Haskell { Add } must always be applied to two elements on the stack.
@PP What we are looking for is a more-or-less generic approach to define
logical and arithmetic operators in @Cat, say, using the @Haskell { Prim (+) }
to frob arithmetic addition from the underlying @Omega implementation.

@LD @Heading { Encountering First Problems }
We could introduce @Haskell { Prim } thus:
@ID @Haskell {
  ...
  Prim :: (a -> b) -> Cat (a, opaque) (b, opaque)
  ...
}
While this approach can surely be made to work with unary functions,
it is not immediately seen how binary @FootNote { or arbitrary arity functions for that matter }
operators can be formalized in the type-safe way mandated by @Omega{.}
The expectation is that a binary primitive would consume the top @Haskell { n } items from the
stack and produce one item as the result.
@LP We have to reformulate our typing rule to deal with the case that
the type parameter @Haskell { b } is in turn a function arrow. Since @Omega
allows us to decompose the arrow's structure using a type function, we try:
@ID @Haskell {
  Prim :: (a -> b) -> Cat {blowUpBy (a -> b) opaque} ({result b}, opaque)
  ...
}
@Haskell { blowUpBy } @FootNote { see the definition of @Haskell { blowUpBy }
and @Haskell { result } in the Appendix @NumberOf { complete.Cat } } creates the expected stack shape needed
for fully saturating the primitive, while @Haskell { result } determines the
rightmost type in the function's arrow type.
With these definitions we can observe the correct type inference of our @Haskell { Add }
substitute @Haskell { Prim (+) }:
@LD {
{ Prim (+) } @Prompt
{ Prim <fn> :: Cat (Int, Int, a) (Int, a) }
}

@LD @Heading { More Problems while Interpreting }
Unfortunately we have not mastered everything yet. We remember that
the semantics of our @Haskell {Cat} combinators is defined by the interpretation
function. So we are obliged to extend @Haskell { interpret' }. We can try thus:

@ID @Haskell operators {Base} @Begin
interpret' [Prim f; rest]l st = do
        (a, st') <- st
        interpret' rest $ return (f a, st')
  where monad ioM
@End @Haskell

But this can only work for @I unary primitives, and since the primitive is allowed to
possess higher arity it cannot typecheck. Clearly, a solution is needed that is able to
distinguish between different-arity primitives at runtime. Since we are not inclined
to introduce a new family of @Haskell { Cat } alternatives, @Haskell { Prim1 }, @Haskell { Prim2 },
etc., we have to equip @Haskell { Prim } with a second argument.

@LD @Heading { Using Representation Types to Describe Arities }
The solution is to attach an object of @I {representation type} to every @Haskell { Prim }
combinator, to aid continued interpretation in the multi-arity case.
@LP To this end we need a description of what types are being passed in
stack slots. This description must be a value so that it can be pattern
matched at runtime and it has to provide a constructor for all tractable
datatypes.

@LD @Haskell {
data Tractable :: * ~> * where
  IntT :: Tractable Int
  BoolT :: Tractable Bool
  CharT :: Tractable Char
  PairT :: Tractable a -> Tractable b -> Tractable (a, b)
  ListT :: Tractable a -> Tractable [a]
  ArrT :: Tractable a -> Tractable b -> Tractable (a -> b)
}

provides a way to describe some data types that are built into @Omega{.} Its
first three constructors apply to basic datatypes, while the rest encodes
rules, how compound datatypes can be represented, given tractable ones.
@PP We can proceed by employing this descriptive facility into our @Haskell { Prim }
constructor:

@ID @Haskell {
  Prim :: Tractable b -> (a -> b) ->
          Cat {blowUpBy (a -> b) opaque}
              ({result b}, opaque)
  ...
}

The first argument to @Haskell { Prim } is called a @I representation{ @FootNote { technically
these types are called @I { singleton types } and constitute a reflection of the structure
of the type-level objects into the value world. }}, becase it records the
structure of the function's range's type{ @FootNote { It suffices to describe the range, because
the domain's type is easily handled without a representation. } }.
@LP We can reproduce our previous @Haskell { Add } primitive now:

@LD {
{ Prim (ArrT IntT IntT) (+) } @Prompt
{ Prim (ArrT IntT IntT) (+) <fn> :: Cat (Int, Int, a) (Int, a) }
}

@LD @Heading { Interpreting Primitives }
We finally have all ingredients together to embark on putting down the @Haskell { interpret' }
case on @Haskell { Prim }. The key idea is here to pattern match on the representation
value in order to incrementally saturate the @Omega function present in the primitive:

@ID @Haskell operators {Base} @Begin
interpret' [Prim (ArrT x y) f; rest]l st = do
        (a, st') <- st
        interpret' [Prim y (f a); rest]l (return st)
  where monad ioM
@End @Haskell

We see that the value popped off the stack is partially applied to the function
and a new primitive is created with the right type representation  and prepended
to the thrist being interpreted. The rest of the possible represented types are
implemented along the lines of our earlier attempt that only covered unary primitives:

@ID @Haskell operators {Base} @Begin
interpret' [Prim IntT f; rest]l st = do
        (a, st') <- st
        interpret' rest $ return (f a, st')
  where monad ioM
@End @Haskell

Unfortunately this code for @Haskell { IntT } must be duplicated for all alternatives
in @Haskell { Tractable } and cannot be wildcarded.
@PP
At this point the interpreter is essentially done, and missing pieces can be filled in
easily.
@End @SubSubSection

@SubSubSection
@Title { Staging the Interpreter }
@Begin
@PP
A well-known technique to turn an interpreter into a compiler
is staging @Cite {$sheard99.staging}. The compile function takes a @Haskell {Thrist Cat} into
a function of the metalanguage, that when executed causes the
same effect as the interpretation of the program itself. Naturally,
the compiled program is expected to run faster, since the interpretative
overhead is already removed.

We demonstrate the technique for one @Haskell {Cat} primitive only{@FootNote
{for a complete implementation consult the Appendix @NumberOf {complete.Cat}}}.

@LD @Haskell operators {Base} @Begin
compile :: Thrist Cat a b -> Code (IO a -> IO b)
compile [Print; rest]l = [| \st -> do
        (a, st') <- st
        putStr $ show a
        $(compile rest) $ return st'
    where monad ioM |]
@End @Haskell

The code pretty much resembles the interpreter, with the main differences being
the @Haskell {[| ... |]} @I {code brackets} and the @I {escaping syntax} @Haskell {$(...)}.
The former allows for constructing values of type @Haskell {Code a} (as seen in the function's
type annotation), and the latter is needed for splicing code into a hole in the code.
Essentially the whole @Cat program gets compiled, which in turn can be executed by
means of the @Haskell {run} function by supplying an initial stack.

@End @SubSubSection

@SubSubSection
@Title { Optimization }
@Begin
@PP
The fact that @Cat programs are represented as data in the metalanguage
that is amenable to analysis by pattern matching, we can write an optimization function
that performs several code optimizations on a program, such as head and tail merging
of conditionals, value folding, inlining etc. Because the @Haskell {Cat} thrist does not admit wrongly
typed @Cat programs and the optimization function takes @Haskell {Thrist Cat} to @Haskell {Thrist Cat},
all optimizations must be type preserving.
@End @SubSubSection

@SubSubSection
@Title { Generalization }
@Begin
@PP
The language @Cat is intended as an intermediate language produced by
front-end compilers and consumed by back-ends that target stack based
virtual machines like JVM @Cite { $jvm.intro } and CIL @Cite { $cil.intro }.
It is advisable to generalize @Haskell {Cat} in a way
that @Haskell {Pop} gets a count parameter that tells how many elements are to be
popped of the stack. Also instead of @Haskell {Swap} it would be beneficial to have
a @Haskell {Permute} primitive that subsumes all variants of stack shuffling operations,
allowing us to get rid of @Haskell {Swap} and friends. All these parametrized primitives
would have one problem in common, namely that the stack shape would
vary depending on the  value of the parameter(s), requiring dependent
types to define them. Fortunately @Omega provides a device that is approaching
the power of dependent types, namely @I {singleton types} and @I {type-level functions}.

Here is a sketch of @Haskell {PopN}:

@ID @Haskell {
  PopN :: Nat' (S n) -> Cat {blow (S n) s} s
}
It uses the type-level function @Haskell {blow} to add the
necessary number of universal type variables
to the initial stack's shape:

@ID @Haskell {
blow :: Nat ~> *0 ~> *0
{blow Z s} = s
{blow (S n) s} = (t, {blow n s})
}

The interpreter can be written thus:

@ID @Haskell {
interpret' [PopN (S n); rest]l st -> do
        (_, st') <- st
        case n of
        0v -> interpret' rest st'
        _ -> interpret' [PopN n; rest]l st'
}

Here we can rediscover the recursion pattern that helped us interpreting
"N-ary" primitives.

@End @SubSubSection

@EndSubSections

@End @SubSection


@SubSection
@Title { Application two: a GADT-based Parser Thrist }
@Begin
@PP
Traditional monadic parser combinator libraries (like Parsec @Cite {$leijen01.parsec}) suffer from the
same problem like the composition operator: they compose easily
but cannot be dissected and analysed, nor translated to other
representations. We proceed similarly to the @Haskell { Thist (->) } and @Haskell { Thrist Cat } to
create a parsing combinator library that is representation agnostic, i.e. built up parsers
can be interpreted"/"compiled and analysed in any reasonable way.



@BeginSubSubSections

@SubSubSection
  @Title { Envisioning Parsing }
  @Tag {envisioning}
@Begin
@PP

But first let's be clear about what we aim at. We demonstrate the process of
parsing by the example of a lexer with semantic evaluation. Our tokens
are the various literal numerals like they occur in the @CLang programming language:
@ID @F {0xCafeBabe 0XE0UL 123456L}
These are the steps we wish to proceed on the second token as the running example:
@List
  style { num) }
  start { 0 }
@ListItem { the token as read from character stream:
@ID @F 0XE0UL
}
@ListItem { we match the @F "0X" prefix:
@ID @F {{@Box 0X}E0UL}
}
@ListItem { we expect zero or more hexadecimal characters:
@ID @F {{@Box 0X}{@Box E0}UL}
}
@ListItem { we check for a non-empty hex string and fold it to a decimal integer:
@ID @F {{@Box 0X}{@CurveBox {@Box E0}}UL}
}
@ListItem { we look for an optional signedness hint:
@ID @F {{@Box 0X}{@CurveBox {@Box E0}}{@Box U}L}
}
@ListItem { we look for an optional storage size specifier:
@ID @F {{@Box 0X}{@CurveBox {@Box E0}}{@Box U}{@Box L}}
}
@ListItem { we encapsulate the distilled information into a token datatype:
@ID {@F @CurveBox {{@Box 0X}{@CurveBox {@Box E0}}{@Box U}{@Box L}}.}
}
@EndList
We can imagine that types play a great role in this process, the small boxes tend
to stand for @Haskell {Char} or @Haskell {[Char]}, while the rounded boxes represent
some @I computed information. We can also observe that several steps @I partition
the input string into a prefix being scrutinized and the as of yet unanalysed rest.
@End @SubSubSection

@SubSubSection
@Title { Realization }
@Begin
@PP
To be able to compose these envisioned operations we define the GADT @Haskell {Parse}:

@TargetForExtract "check/Parser.incomplete1"
@IgnoreForOutput @Haskell @Begin
import "LangPrelude.prg"
data Thrist :: (* ~> * ~> *) ~> * ~> * ~> * where
  Nil :: Thrist p a a
  Cons :: p a b -> Thrist p b c -> Thrist p a c
 deriving List(l) 
@End @Haskell

@LD @Haskell @Begin
data Parse :: * ~> * ~> * where
  Atom :: Char -> Parse Char Char
  Sure :: (a -> b) -> Parse a b
  Try :: (a -> Maybe b) -> Parse a b
  Rep1 :: Parse a b -> Parse [a] ([b], [a])
  Rep :: Parse [a] (b, [a]) -> Parse [a] ([b], [a])
  Group :: [Parse a b] -> Parse [a] ([b], [a])
  Par :: Parse a b -> Parse c d -> Parse (a, c) (b, d)
  Wrap :: Thrist Parse a b -> Parse a b
@End @Haskell

The datatype @Haskell { Parse a b } represents a parser that consumes data of type @Haskell { a }
and if a match is found it produces a value of type @Haskell { b }. The types mentioned in the
constructors already give us a strong indication about their intended meaning:

@DashList
@ListItem {  @Haskell {(Atom 'X')} matches only the capital @Haskell {'X'} character }
@ListItem {  @Haskell {(Sure ord)} alway matches, consuming a @Haskell {Char} and returning its @Haskell {Int} ASCII value }
@ListItem {  @Haskell {(Try hexdigit)} matches only if a character is a hexadecimal one and returns its hex value, fails otherwise }
@ListItem {  @Haskell {(Rep1 (Atom 'X'))} matches as many capital @Haskell {'X'}s as possible and returns a pair consisting the matched and unconsumed portions }
@ListItem {  @Haskell {(Rep part)} similarly tries to match as many @Haskell {part}s in the input's prefix as possible }
@ListItem {  @Haskell {(Group [Atom 'a', Atom 'b'])} just matches a prefix @I {''ab``} in the input, returning it in a pair along with the unconsumed portion, or fails otherwise }
@ListItem {  @Haskell {(Par fst snd)} runs @Haskell {fst} and @Haskell {snd} on the two components of the pair, failing if any of them fails }
@ListItem {  @Haskell {(Wrap parseThr)} simply allows to treat a thrist as a @Haskell {Parse}. }
@EndList

In the above descriptions we only suggest a possible semantics, because @Haskell {Parse}
does not mandate it in any way. So when we talk about ''returns something`` then this is just an intention,
an implementation may choose to employ an other strategy (such as @I {continuation passing}). It
is also completely unspecified what @I failure and @I success actually entail.
@PP
Proceeding with our running example, we expect the end result of token parsing to produce a value of the
following @Haskell {Token} data type:

@ID @Haskell @Begin
data Token =
  Number Int Bool Bool
  | ...
@End @Haskell
This amounts to our parser consuming a string and producing @Haskell {Token}s (along with the unconsumed rest)
to be assigned the type @Haskell {Thrist Parse [Char] ([Token], [Char])}.

@End @SubSubSection

@SubSubSection
@Title { Using the Combinators }
@Begin
@PP
How can we use our combinators to describe the parsing steps 0) to 6) from the Section @NumberOf {envisioning}?
@BulletList

@ListItem { First, we use
@Haskell {Group [Atom '0', Atom 'X']}
to match the prefix of the string @Haskell {"0XE0UL"} and
produce @Haskell {("0X", "E0UL") :: ([Char], [Char])}.
}

@ListItem { Then we can discard the prefix because at this point we know
that we have to do a base 16 conversion later.
We employ @Haskell {Sure snd} to do this, obtaining @Haskell {"E0UL" :: [Char]}.
}

@ListItem { Then @Haskell {Rep1 (Try hexdigit)}
will split off two more characters, converting them to decimal values on the way.
So far we've got @Haskell { ([14, 0], "UL") :: ([Int], [Char]) }.
}

@ListItem { Since we cannot discard either component, we have to proceed in parallel with
@LD @Haskell {
Par (Wrap [Try nonEmpty, Sure foldHex]l)
    (Wrap [Rep1 $ Atom 'U',
          Par (Sure id)
              (Rep1 $ Atom 'L')]l)
}
where the first component produces 224, and the second goes on by splitting off any @Haskell { 'U' } 
followed by any @Haskell { 'L' }, producing a triple @Haskell { ("U", ("L", "")) }.
At this stage we have @Haskell {(224, ("U", ("L", ""))) :: (Int, ([Char], ([Char], [Char])))}.
}

@ListItem { Finally, we feed this into @Haskell {Try numberToken}
that verifies the correct usage of 'U's and 'L's, and creates a pair
@Haskell {(Number 224 True True, "") :: (Token, [Char])}
consisting of the parsed token and the rest of the input.
}
@EndList

We have not yet given the defininitions of the @Haskell {hexdigit}, @Haskell {foldHex},
@Haskell {nonEmpty} and @Haskell {numberToken} functions. These follow next and should
be rather obvious.

@ID @Haskell @Begin
hexdigit = \c -> if ord '0' <= ord c && ord c <= ord '9'
                   then Just (ord c - ord '0') else
                 if ord 'a' <= ord c && ord c <= ord 'f'
                   then Just (ord c - ord 'W') else
                 if ord 'A' <= ord c && ord c <= ord 'F'
                   then Just (ord c - ord '7') else Nothing

foldHex = foldl (\acc x -> (acc * 16) + x) 0

nonEmpty (all@(_:_)) = Just all
nonEmpty _ = Nothing

numberToken :: (Int, (String, (String, String))) -> Maybe (Token, String)
numberToken (i, ("", ("", rest))) = Just (Number i False False, rest)
numberToken (i, ("U", ("", rest))) = Just (Number i True False, rest)
numberToken (i, ("", ("L", rest))) = Just (Number i False True, rest)
numberToken (i, ("U", ("L", rest))) = Just (Number i True True, rest)
numberToken _ = Nothing
@End @Haskell

Putting all together we can write:
@ID @Haskell @Begin
signedSized = Wrap [Rep1 (Atom 'U'), Par (Sure id) (Rep1 (Atom 'L'))]l

hexToken =
  [ Group [Atom '0', Atom 'X']
  , Sure snd
  , Rep1 (Try hexdigit)
  , Par (Wrap [Try nonEmpty, Sure foldHex]l) signedSized
  , Try numberToken ]l

tokens = Rep (Wrap hexToken)
@End @Haskell

With some squinting we can summarize the principles as:
@DashList
   @ListItem { The interesting prefix is split off the rest, }
   @ListItem { if it is semantically important we condense it to a more appropriate form, }
   @ListItem { resorting to parallel processing if both components of an input pair are relevant. }
@EndList

As the execution of the thrist proceeds, incrementally more of the token are analysed, condensed and converted.

######################## THIS FIGURE SHOULD SHOW UP IN A DIFFERENT PLACE #############################
@TargetForExtract "check/Machine.part2"
@Figure
    @Tag { machine }
    @Caption { State machine fragment }
@Diag # vstrut { yes } treehsep { 1c }
      outline { curvebox }
      nodelabelfont { Slope -2p }
      linklabelformat { "/"@Body"/" } 
{



    # @HTree { @Box Lout @FirstSub arrow { yes } @Box PostScript }

@Tbl
    aformat { @Cell indent { ctr } iv { ctr } A | @Cell indent { ctr } iv { ctr } B }
    bformat { @Cell indent { ctr } width { 3c } height { 1.15c } A | @Cell indent { ctr } height { 1.15c } B | @Cell indent { ctr } height { 1.15c } C }
    marginhorizontal { 0.5c }
    marginvertical { 0.25c }
{
@Rowa
    A { NW:: @Node NorthWest }
    B { N:: @Node North }
@Rowa
    A { W:: @Node West }
    B { M:: @Node Mid }
@Rowb
    B { S:: @Node South }
    C { SE:: @Node SouthEast }
}

||1f { Base -2p } @Font @Tbl
    aformat { @Cell A }
{
@Rowa
    A { @Haskell @Begin
northWest :: State GateClosed SecondaryEnabled (H Idle Idle')
        @End @Haskell }
@Rowa
    A { @Haskell @Begin
north :: State GateClosed SecondaryEnabled (H Idle Idle')
        @End @Haskell }
@Rowa
    A { @Haskell @Begin
west :: State GateClosed SecondaryEnabled (H Idle NeedAck)
        @End @Haskell }
@Rowa
    A { @Haskell @Begin
mid :: State GateClosed SecondaryBlocked (H Idle NeedAck)
        @End @Haskell }
@Rowa
    A { @Haskell @Begin
south :: State GateClosed SecondaryBlocked (H Idle Idle')
        @End @Haskell }
@Rowa
    A { @Haskell @Begin
southEast :: State GateOpen SecondaryBlocked (H Idle Idle')
        @End @Haskell }
}


//
@Arrow from { NW } to { N } ylabel { req } ylabelctr { no }
@Arrow from { N } to { M } ylabel { plug } ylabelctr { no }
@Arrow from { NW } to { W } ylabel { plug } ylabelctr { no }
@Arrow from { W } to { M } ylabel { req } ylabelctr { no }
@Arrow from { W } to { S } ylabel { ack }
@Arrow from { M } to { SE } ylabel { ack }
@Arrow from { S } to { SE } ylabel { req } ylabelctr { no }
}

@End @SubSubSection

@SubSubSection
@Title { Defining the Semantics by Interpretation }
@Begin
@PP
We provide the @Haskell {parse} function for the @Haskell {Rep} constructor as an example:

@TargetForExtract "check/Parser.incomplete2"
@LD @Haskell @Begin
parse :: Thrist Parse a b -> a -> Maybe b

parse [Rep p; r]l as = parse r (parseRep [p]l as)
    where
      parseRep :: Thrist Parse [a] (b, [a]) ->
                      [a] -> ([b], [a])
      parseRep _ [] = ([], [])
      parseRep p as = case parse p as of
                      Nothing -> ([], as)
                      Just (b, as') -> (b:bs, rest)
                        where (bs, rest) = parseRep p as'
@End @Haskell
This code is rather unsurprising: to obtain a list of @Haskell {p}s
we have to consume as many parsed constituents from the input as possible
and accumulate them in the result along with the remaining input.
@PP
For the rest of the implementation we defer to Appendix @NumberOf { parsing.token }
which contains a working example for parsing hexadecimal tokens.

@End @SubSubSection

@SubSubSection
@Title { Compilation }
@Begin
@PP
In a fashion similar to the @Haskell {Thrist Cat} we can compile our parser combinators to
a more efficient algorithm by removing the interpretative overhead. We have complete freedom
in the selection of implementation methodology: we can target the object language directly
or plumb monadic- resp. arrow-based parser combinators.

@End @SubSubSection

@SubSubSection
@Title { Analysis }
@Begin
@PP
We can run various analyses on our parsers, to ensure that the grammar is unambiguous, for example.
A popular transformation would be the detection of left-recursion and its transformation to a right-
recursive form.

@End @SubSubSection

@SubSubSection
@Title { Outlook }
@Begin
@PP
Many interesting other combinators can be defined, my repository contains also
@LD @Haskell {
  Seq :: Parse [a] (b, [a]) -> Parse [a] (c, [a]) -> Parse [a] ((b, c), [a]) -- parse front first then second
  Seq1 :: Parse a b -> Parse a c -> Parse [a] ((b, c), [a]) -- same, but with single-elem first and second
  ButNot1 :: Parse a b -> Parse a b -> Parse a b     -- match first and expect second to fail
  UpTo :: Parse [a] (b, [a]) -> Parse [a] (c, [a]) -> Parse [a] ((b, c), [a]) -- scan for c then match b
}
etc.

I think working together with a parsing expert could result in a minimal set of combinators that
allow parsing a great variety of grammars and optimization and compilation methods that make
the parsing process *fast*.
@End @SubSubSection

@EndSubSubSections

@End @SubSection


@SubSection
@Title { Application three: Actions on State Machine Transitions }
@Begin
@PP
One popular use of metaprogramming tools is generating code for legacy
systems, especially when the high-level language's whole feature set is
too heavy for the application, such as in embedded systems with significant
resource limitations. We wish a system where very strong guarantees are maintained
in the model by resorting to typeful data representation and nevertheless
preserve the ability to convert our model into a lower-level representation
that is feasible for the target system.

@BeginSubSubSections


@SubSubSection
@Title { The Transition System }
@Begin
@PP
Figure @NumberOf { machine } depicts a fragment of a state machine intended to handle
@I { request"/"acknowledge } type handshake with an identical remote instance
of itself. The two instances are communicating solely by message passing
and originally both inhabit the @I NorthWest state. The intention is that the
two machines control the ends of a unidirectional communication channel
that is {@I protected}, i.e. two wires exist, carrying a data stream A on the
first wire{ @FootNote {the second wire can either carry the same data as A (to increase redundancy),
or the two wires could jointly carry stream A (to increase bandwidth)} },
and when the first wire does not carry data, the second wire can
be utilized to carry a lower-priority data stream B. The typical use-case
is the premium customer paying for A and the bulk customer paying significantly
less for B. There is an extra twist however: it is forbidden for the data stream A
to reach the sink of data stream B, even for very short time periods. This invariant
calls for the request"/"acknowledge handshake, and the transient states on the way to
the @I SouthEast state mirror this protocol.

@End @SubSubSection



@SubSubSection
@Title { Typed States }
@Begin
@PP
We intend to equip the states with an orthogonal system of properties
(which we call {@I facets}), and hope to assemble transition arrows
from a toolbox of elementary actions which deal with a minimal number
of facets each.
To formally introduce the facets, we employ another @Omega feature,
namely @I { user-defined kinds }, whose alternatives can be used to
parameterize the @Haskell { State } datatype:
@TargetForExtract "check/Machine.part1"
@LD @Haskell @Begin
kind Gate = GateClosed | GateOpen
kind Secondary = SecondaryEnabled | SecondaryBlocked
kind HandshakeIn = Idle | Requested
kind HandshakeOut = Idle' | NeedAck
kind Handshake = H HandshakeIn HandshakeOut

data State :: Gate ~> Secondary ~> Handshake ~> * where
  State :: [Transition g s h] -> State g s h
@End @Haskell

Figure @NumberOf { machine } includes the states along with the facets and
the labeling of the transition lists the actions needed e.g. to ensure the working
of the handshaking protocol. For now we leave the definition of @Haskell {Transition}
open, we shall supply it in due time.
@End @SubSubSection

@SubSubSection
@Title { Triggers as Obligations }
@Begin
@PP
The state machine holds a distinguished state at any time. Triggers acting on the machine
are used to initiate a change of the current state. Additionally, triggers can impose
certain constraints that need to be dealt with during the actual transition. To encode
triggers we introduce{@FootNote {the code is not syntactically correct
(@Omega has no pairs at the kind level), but demonstrates our point}}:

@ID @Haskell @Begin
data Obligation :: (Gate Secondary Handshake) ~> (Gate Secondary Handshake) ~> * where
  TriggerExclusive :: Obligation (a, b, H Idle c) (a, b, H Requested c)
  TriggerAck :: Obligation (a, b, H c NeedAck) (a, b, H c Idle')
  TriggerPlugged :: Obligation (GateClosed, b, H Idle c) (GateClosed, b, H Idle c)
  ...
@End @Haskell

From the type signatures we can deduce that e.g. the @Haskell {TriggerAck} clears
the @Haskell {NeedAck} facet on the current state. On the other hand if the
obligation raises some facet that corresponds to none of the possible states,
then the subsequent action is in charge to clear this facet. To wit @Haskell {TriggerExclusive}
above does raise @Haskell {Requested}, but no state in Figure @NumberOf { machine }
has such a facet listed. To obtain a transition system that passes the type checker
some action must turn the @Haskell {Requested} back to @Haskell {Idle}. We'll talk about
transition actions next.
@End @SubSubSection


@SubSubSection
@Title { Action Thrists }
@Begin
@PP
Actions associated with state transitions can be arbitrarily complex, so instead of
putting down a monolythic action for each transition arrow, we wish to modularize
our actions. To this end we break down monolithic blocks into @I {elementary actions}
that also carry facets, so the typing constraints can be easily enforced.
We choose to implement the elementary actions as a GADT:

@ID @Haskell @Begin
data Action :: (Gate, Secondary, Handshake) ~> (Gate, Secondary, Handshake) ~> * where
  RequestExclusive :: Action (a, b, H c Idle') (a, b, H c NeedAck)
  AckExclusive :: Action (a, b, H Requested c) (a, b, H Idle c)
  OpenGate :: Action (GateClosed, SecondaryBlocked, c) (GateOpen, SecondaryBlocked, c)
  BlockSecondary :: Action (a, SecondaryEnabled, c) (a, SecondaryBlocked, c)
  ...
@End @Haskell

Given this definition of elementary actions we can apply our thrist framework
and form thrists from these. Then state transitions would correspond to three ingredients:
@List
   @ListItem { they originate from a state, }
   @ListItem { select a possible transition arrow given a trigger, }
   @ListItem { and finally execute a @Haskell { Thrist Action } to arrive at the target state. }
@EndList

We define:

@ID @Haskell @Begin
data Transition :: Gate ~> Secondary ~> Handshake ~> * where
  From :: State g' s' h' ->
          Obligation (g', s', h') (g'', s'', h'') ->
          Thrist Action (g'', s'', h'') (g, s, h) ->
          Transition g s h
@End @Haskell

We have fulfilled our earlier promise, and now we can define @Haskell {State}s.
For instance the @Haskell { south } state could be defined thus:
@ID @Haskell @Begin
south = State [From west TriggerAck [BlockSecondary]l]
@End @Haskell

We have succeeded in providing a very compact representation of state machines.
From the above expression we can see that only one transition arrow arrives at @Haskell { south }, how
it is triggered and which action follows. The fact that the type checker allows
this expression is an additional assurance of correctness.

@PP
What do we gain with such a declarative description of the state machine at
hand?
@DashList
   @ListItem { First, given a fine-grained encoding of the protocol's and business logic's
encoding in the state facets, the type system will take care of checking that
all necessary elementary actions are mentioned in the transition's action thrist.
This can be an important assurance in case of great statemachines with a complicated
semantic model. Especially for communicating state machines, as in our example,
the administrative states arising as a result of the handshaking protocol
can be daunting. Getting the transition actions right between all these states
is an error prone task and help from the type system highly welcome. }
   @ListItem { Second, the possibility to pattern-match on the actions that form transitions
it is possible to enumerate all possible admissible configurations of the communicating
state machines and use proof techniques to ensure that the principal invariant of
the system is met. }
@EndList

@End @SubSubSection


@EndSubSections

@End @SubSection



@EndSubSections

@End @Section





@Section
  @Title { Exotic Uses }
@Begin
@PP
We have already seen @Haskell { Thrist (,) } and @Haskell { Thrist (->) } in the introduction.
But several more common two-parameter datatypes exist that @Haskell { Thrist } can be parametrized with,
e.g. @I Either{@FootNote { in @Omega named as @Haskell { (+) } }}, @Haskell { Equal } and so on.
In this section we analyse the formal requirements for inclusion into the @Haskell { Thrist } framework,
constructing adapters as needed, and suggest possible uses.

@BeginSubSections

@SubSection
  @Title { Equal Thrist }
@Begin
@PP
In @Omega the @Haskell { Equal } datatype has two parameters, and is used to
track type equality internally. The @I { Curry-Howard correspondence } is employed
to prove propositions encoded in the types of functions, and the resulting @Haskell { Equal }
types can be introduced by @I { theorem declarations } into the type-checker's
rewrite engine. Typical and useful instantiations of @Haskell { Equal } arise in connection
with type functions, e.g. @Haskell { Equal {plus a b} {plus b a} } which is a manifestation
of the @Haskell { plus } type function's commutativity.
@LP When we assert @Haskell { lemma :: Thrist Equal a a } and @Haskell { lemma } is a
thrist of length greater or equal to 2, then the following function @Haskell { trans }
can be applied to get a proof object by transitivity:

@TargetForExtract "check/Curious"
@ID @Haskell @Begin
trans :: Thrist Equal a b -> Equal a b
trans []l = Eq
trans [eq; rest]l = case (eq, trans rest) of
                    (Eq, Eq) -> Eq
@End @Haskell

Since the elementary proof objects that are lined up in the thrist already have their types
aligned where they meet, it is easy to contract the whole thing to a single witness.

@PP
One could go a step farther and consider a @Haskell {(=>)}{@FootNote {imaginary @Omega operator} }
relation as a binary datatype, with constructors that encode the implication.
Then @Haskell { circ :: Thrist (=>) a a } could encode circular implications, equating
all intermediate types (propositions).
@PP
With this speculative note we leave the realm of curiosity and turn
our attention to interesting and useful abstractions that are already
part of the functional programmer's weaponry.
@End @SubSection

@SubSection
  @Title { Connection to Arrows and Monads }
  @Tag { section.arrow-monad }
@Begin
@PP

@Figure
    @Tag { binary }
    @Caption { Mathematical structures with binary inner operation }
@Tbl
    ruleabove { yes }
    ruleabovecolour { darkgrey }
    ruleabovewidth { 0.02f }
    aformat { @Cell indent { ctr } iv { ctr } @B A
            | @Cell indent { ctr } iv { ctr } @B B
            | @Cell indent { ctr } iv { ctr } @B C
            | @Cell indent { ctr } iv { ctr } @B D
            | @Cell indent { ctr } iv { ctr } @B E
            | @Cell indent { ctr } iv { ctr } @B F }
    bformat { @Cell indent { ctr } A
            | @Cell indent { ctr } B
            | @Cell indent { ctr } C
            | @Cell indent { ctr } D
            | @Cell indent { ctr } E
            | @Cell indent { ctr } F }
{
@Rowa
    A { Name }
    B { Associative? }
    C { Identity? }
    D { Total? }
    E { Invertible? }
    F { Commutative? }
@Rowb
    A { Monoid }
    B { yes }
    C { yes }
    D { yes }
    E { no }
    F { no }
@Rowb
    A { Semigroup }
    B { yes }
    C { no }
    D { yes }
    E { no }
    F { no }
@Rowb
    A { Category }
    B { yes }
    C { yes }
    D { no }
    E { no }
    F { no }
@Rowb
    A { Groupoid }
    B { yes }
    C { yes }
    D { no }
    E { yes }
    F { no }
@Rowb
    A { Group }
    B { yes }
    C { yes }
    D { yes }
    E { yes }
    F { no }
}


In the Haskell world, @I arrows @Cite { $hughes00.arrows } also originate from the attempt to generalize function
composition. It is helpful to give a comparison of the @Haskell { Arrow } @I { type class } in Haskell and
our @Haskell { Thrist } definition. 

It is fairly easy to see how the Haskell type class @Haskell { Arrow } can be expressed as a thrist.
Here is a stripped-down definition of @Haskell { Arrow } to its essence:
@ID @Haskell {
class Arrow a where
  arr :: (b -> c) -> a b c
  (>>>) :: a b c -> a c d -> a b d
  first :: a b c -> a (b, d) (c, d)
}
The first method (@Haskell {Arrow}) is taking an ordinary  function into the arrow, the second
@Haskell {(>>>)} can be regarded as composition and the third (@Haskell {first}) defines the
interaction between arrows and pairs. As we have already stated in the introduction (@NumberOf {intro.compose}),
@Haskell { Cons } already provides the r{@Char ocircumflex}le of @Haskell {(>>>)}.
To cover the remaining two, all we have to do is to define a three-parameter datatype with two data
constructors @Haskell {Arr} and @Haskell {First}:
@LD @Haskell {
data Arrow' :: (* -> * -> *) -> * -> * -> * where
  Arr :: (b -> c) -> Arrow' a b c
  First :: Arrow' a b c -> Arrow' a (b, d) (c, d)
}

To obtain the arrow {@I behaviour}, we have to accompany the @Haskell { Thrist Arrow' }
with an interpretation function that guarantees the arrow laws @Cite { $hughes00.arrows }.
Fortunately such a semantics can be canonically defined in terms of the enclosed
arrow's methods. Please consult Appendix @NumberOf { arrow.adapter } for a slightly
different, but complete implementation.
@PP
As we can see now, thrists (along with an appropriate semantics) do generalize arrows,
on the other hand they are not always easily fitted in an arrow.
It is the @Haskell { arr } method that is problematic to provide.
Thrists just serve as a container and do not carry a semantics per se, while @Haskell { Arrow }
instances mandate a function argument for the method @Haskell { arr }.
@PP
Monads can also be regarded as a specialization to arrows, so we expect that @Haskell { Thrist (Monad' T) }
can be canonically derived. Here @Haskell { Monad' T a b } represents the type of a monadic actions
either starting afresh and resulting a monadic value @Haskell { T b } or representing a Kleisli arrow
@Haskell { a -> T b }.
@LP We can define the adapter @Haskell { Monad' } to have three parameters, the first fixing the @Haskell { Monad }
and the last two to accomodate for the @Haskell { Thrist } interface:
@LD @Haskell {
data Monad' :: (* ~> *) ~> * ~> * ~> * where
  Feed :: m b -> Monad' m a b
  Digest :: (a -> m b) -> Monad' m a b
}
Here @Haskell {Feed} can be regarded as the moral equivalent of the monadic @Haskell { return },
while @Haskell {Digest} stands for the @I bind operation @Haskell { (>>=) }.
@LP Again, we have to provide a semantics, to make the embedding complete:
@LD @Haskell {
runM' :: Monad m -> m a ->
         Thrist (Monad' m) a b -> m b
runM' _ seed []l = seed
runM' v _ [Feed m; rest]l = runM' v m rest
runM' (v@Monad _ bind _) seed [Digest f; rest]l
         = runM' v (bind seed f) rest
}
Some words of explanation are in order. For technical reasons @Haskell {runM'} receives a monadic
@I seed argument, this allows to implement the @Haskell {Feed} and @Haskell {Digest} alternatives
by simple recursion. The presence of the first argument compensates for a current deficiency
of @Omega (namely the lack of type classes), and is needed for explicit passing of the @Haskell {Monad}
dictionary.
@PP
We will stop here, but not without mentioning that recent research has established
a connection between dataflow programming and its elegant reformulation using
@I comonads @Cite { $uustaluvene05.dataflow }. An adapter for comonads is just
as straightforward to put down as @Haskell { Monad' } above.
@End @SubSection


@SubSection
  @Title { Connection to Categories }
@Begin
@PP
When looking at the Wikipedia page @Cite {$wikipedia.groupoid} that explains mathematical
structures possessing a binary operation, we can make an attempt to gain some insight
of how thrists can be fitted in a niche. Obviously, the @I associativity property holds,
like for lists, it is impossible to distinguish thrists appended @FootNote {see Appendix @NumberOf { append }}
as long the ordered sequence of elements is pointwise equal. For reference, the table
of mathematical structures with an associative binary operation is reproduced in Figure @NumberOf { binary }.
Clearly, the @Haskell {Cons} operation mandates an order, so @I commutativity cannot hold.
Also, not every datatype that can serve as a first parameter to @Haskell {Thrist} has an inverse,
even when disregarding any semantics and concentrating on the types of its constructors.
So it remains to find out whether totality holds to settle on the exact concept. Can we always
form a new thrist by appending two arbitrary thrists? The answer is clearly @I {no}, as we
have already stated several times, the typing rule for the @Haskell {Cons} operation may interfere.
So, looking up the concept with these properties in Figure @NumberOf { binary }
brings us straight to @I {category} @Cite {$wikipedia.category}.
Looking at it from another angle we can imagine @I {directed graphs}, and thrists corresponding
to any @I path between two @I {nodes}, respecting directionality. But this is nothing new, as
directed graphs and categories are the same concept.
There is still something missing, though. For a mathematical structure to be a category: each object
must have a corresponding @I {identity morphism}. This is not in general fulfilled for
an arbitrary datatype that is passed to @Haskell {Thrist}, but is it possible to obtain it for
@Haskell {Thrist p} for an admissible @Haskell {p}?
@PP
Let's look at the problem from another angle first. The type-threaded nature of the
@Haskell {Thrist} datatype is the distinguishing feature of @I { free categories } @Cite { $maclane.working }
too. In the Appendix @NumberOf { append } we supply an @Haskell { appendThrist } function that can be regarded
as the inner multiplication operation (concatenation) in the free category. So,
a free category is a free monoid @Cite { $wikipedia.free-monoid } over an arbitrary category C
where C's available morphisms restrict concatenation, or simply put, words formed from objects of C
with consecutive letters having an arrow in C between them. The @Haskell {Thrist}'s typing rule very much
tells the same story, and @Haskell {Nil :: Thist p a a} is obviously the identity
under @Haskell { appendThrist }. So we have shown @Haskell {Thrist p} to be a category,
which happens to be a free category C* if the datatype @Haskell {p} is isomorphic to C.
@End @SubSection


@EndSubSections
@End @Section


@Section
  @Title { Other Work }
@Begin
@PP
David Roundy's @I { Darcs } @Cite { $roundy.darcs2 } is a version control system
which builds upon a @I {theory of patches} @Cite { $wikibooks.patch }, defining
the evolution of data repositories (and of documents therein) as a gradual application
of individual changes. The recent adoption
of GADTs into the system has led to a two-parameter @Haskell {Patch} datatype and
@Haskell {FL}, @Haskell {RL} GADTs which are used for sequencing these (among others).
The definition of @Haskell {FL} is identical to how our @Haskell {Thrist} would be
defined in Haskell! Being hidden in a utility module, @Haskell {FL} entered the @I { Darcs }
codebase in the year 2007 but its origins can be traced back to a brain-storming session at
@I {Haskell'05} workshop in Tallinn.
@PP
In his @I {Fun in the Afternoon} talk @Cite {$mcbride07.rstar}, Conor McBride proposed
the free category {@I R}* as generalization to the conventional list datatype and several others.
At the heart of the matter, his @I R stands  for the first parameter to our @Haskell {Thrist},
while the ''*`` is borrowed from the mathematical notation for free categories, and thus essentially
our @Haskell {Thrist} type constructor together with the @Haskell {appendThrist} operation.
To demonstrate his point,
@ID @Haskell {
data List' :: * ~> * ~> * where
  Elem :: a -> List' a a
}
is a similar adapter to the one in Section @NumberOf { section.arrow-monad } and @Haskell {Thrist List'} is the
datatype McBride proposes as the new list type. In this special case we really obtain
a free category, since @Haskell {List'} defines identity morphisms.
@PP
Ever since the invention of Lisp the program-as-data idiom has been a treasure trove for functional programmers.
Chuan-kai Lin's @I { Unimo } framework @Cite { $lin06.unimo } is an attempt to describe monads operationally
by interpreting a datastructure that describes the monad. By the fact that the interpreter
is proven to satisfy the monadic laws, a guarantee is given that the monadic semantics
is fulfilled, regardless what callback functions the monad's creator supplies.
GADTs appear in his work only as the datatypes modelling the @I { effect basis } of monads,
while they are not needed for the general case.
@PP
Another example of the rekindled interest in modelling side-effecting computations in a purely functional
manner is given by the Haskell Workshop paper of Swierstra et al. @Cite { $swierstra07.beast }, which demonstrates
another use of the @I { free monad }, a data structure built up as an ADT. The result can be examined intensionally
by pattern matching, in a similar fashion like our thrists can be taken apart by the semantics functions.
@PP
Chris Heunen and Bart Jacobs' work @Cite { $heunenjacobs.monoid } on the connection of arrows and monads
and their category theoretical formalisation is of relevance because it reveals the mathematical
structure behind these constructs, giving a common generalization to them as {@I monoids}.
Arrows @Cite { $hughes00.arrows } appeared in the general mindset as a pragmatic approach to deal with
a certain class of parsers that did not fit into the monadic framework @Cite { $duponcheel96.parser }.
Nilsson @Cite { $nilsson05.frp } provides a method for optimizing limited cases of arrow combinator libraries using GADTs.
In the scope of framework for functional reactive programming he is still bound to the limitations of the amesiac nature of
function composition inside the arrow, but seem to gain some noticeable gains in performance especially with microbenchmarks
modelling the arrow laws.
@End @Section

@Section
  @Title { Conclusion and Further Work }
@Begin
@PP
We have found a way to generalize function composition by separating its
type structure from its semantics. The data structure we suggest is a
GADT with two constructors strongly resembling classical lists, but with a
side-condition that the types must be threaded. The semantics is provided by
an interpretation function that can be provided separately for each first parameter
of the @Haskell {Thrist} type constructor.

@PP We have provided three examples for the usefulness of the thrist data
structure and demonstrated that the ability to take thrists apart and analyse is
a very good arguments for their use. Also, all operations performed on thrists, such
as subdivision, insertion and extension must be performed by algorithms that preserve
the strong typing constraints that are imposed by the @Haskell { Thrist } type constructor's
typing rule. For this to work, it is crucial that @Haskell { Thrist } is defined to be
a generalized algebraic datatype (GADT).

@PP We have further shown that thrists generalize arrows naturally and monads with
a shallow adaptation layer. We have identified free categories to be the closest
relative of our thrists in the mathematical realm.
@PP Last, but not least, we could successfully exploit {@Omega}'s extensible syntax
to present thrists in a uniform and aestetical way, well alike {@I Haskell}'s syntax
for lists, with the same ease of pattern matching and construction.
@PP
Although the above provides sufficient evidence of the usefulness of thrists, there
is still plenty to find out.
@LP What other useful @Haskell {p}s in @Haskell { Thrist p a b } exist?
Since the @Haskell {a} and @Haskell {b} parameters can encode
propositions, the @Haskell { Thrist } approach can convey the evolution
of abstract properties, e.g. the adherence to the SSA form @Cite {$appel98.ssa}.
Modern compiler architectures{ @FootNote { GCC @Cite {$gcc.ssa} and LLVM @Cite {$llvm.intro} being notable representants } }
tend to favor this formalism for internal representation of imperative programs.
Explicitly tracking @I {def-use} information paired with annotation preserving
transformations might pave the way to certified compilers, but appears to
be a challenging task.
@LP A similar question is that of restricted monads. Is it possible to provide a
more generic adapter than the one presented in Section @NumberOf {section.arrow-monad},
that encompasses restricted monads too?
@LP LLVM @Cite {$llvm.intro} has a @I getelementpointer instruction, which allows to do offset calculations
into deeply nested ({@CLang}-style) data structures. The descent from the encompassing pointer, array or
structure type to the desired structure member can be conveniently encoded as a thrist,
where the underlying GADT provides constructors for dereferencing of pointers, picking of array elements
and skipping over (resp. selecting) of structure members. The resulting thrist can then
easily converted into the sequence of integers that is encoded in the @I getelementpointer instruction.
@LP @I Parametricity is a powerful weapon in proving program properties. It seems a worthwile direction
of research to find out which sensible algorithms on thrists exist on @Haskell { Thrist p a b }, where
p is left universal. At first glance maps and folds seem to break because of the typing rule, but
studying the correspondig free categories might show the way. As these transformations are essential
for a wide range of regular data structures, we should be able to use similar higher-order functions too.
@LP While the syntax presented here is already quite palatable, it remains to be seen how thrists can be
given syntactic sugar along the lines of the monadic ''do`` (or even arrow{
@FootNote { @I {arrow syntax} @Cite { $paterson01.notation } is available in certain Haskell implementations, but not in @Omega}}) notation
used in current Haskell implementations.
@PP We intend to tackle these theoretical and practical questions as a follow-on.
@End @Section


@Section
  @Title { Acknowledgements }
@Begin
@PP
My special thanks go to Tim Sheard, whose @Omega system served as an
excellent testbed for formulating the ideas expressed in this paper.
The @I { HaL 2 } workshop gave me the opportunity to discuss the connection
between categories and thrists, thanks to Heinrich-Gregor Zirnstein,
for encouragement and to Johan Jeuring for constructive criticism.
Christopher Diggins corrected some of my views on the @Cat language and
provided valuable input for the presentation. Ganesh Sittampalam told the
story of thrists in darcs and gave the final impulse to get this paper
published.
@End @Section


@Appendix
  @Title { Useful Functions on Thrists }
@Begin
@PP
Following functions are parametric in the thrist type, i.e.
in the first type parameter to the thrist. Thus they are universal.

@BeginSubAppendices

@SubAppendix
  @Title { Extending }
@Begin
@LD @Haskell {
extendThrist :: forall (a :: *1) (b :: a ~> a ~> *0) (c :: a) (d :: a) (e :: a).
                Thrist b c d ->
                b d e ->
                Thrist b c e

extendThrist []l a = [a]l
extendThrist [b; r]l a = [b; extendThrist r a]l
}
@End @SubAppendix

@SubAppendix
  @Title { Appending }
  @Tag { append }
@Begin
@LD @Haskell {
appendThrist :: forall (a :: *1) (b :: a ~> a ~> *0) (c :: a) (d :: a) (e :: a).
                Thrist b c d ->
                Thrist b d e ->
                Thrist b c e

appendThrist []l a = a
appendThrist [b; r]l a = [b; appendThrist r a]l
}
@End @SubAppendix

@SubAppendix
  @Title { Flattening }
@Begin
@LD @Haskell {
flattenThrist :: Thrist (Thrist k) a b -> Thrist k a b

flattenThrist []l = []l
flattenThrist [a; as]l = appendThrist a $ flattenThrist as
}
@End @SubAppendix

@SubAppendix
  @Title { Instrumenting }
@Begin
@PP
It might be useful to wrap each thrist member with
a special instrumentation, e.g. for tracing (tracepoints)
or other ways of debugging.
@LP Following function (using rank-2 polymorphism) accomplishes this.
@LD @Haskell {
intersperseThrist :: (forall (x :: *). k x x) -> Thrist k a b -> Thrist k a b

intersperseThrist i []l = [i]l
intersperseThrist i [a; as]l = [i, a; intersperseThrist i as]l
}
@End @SubAppendix

@EndSubAppendices


@End @Appendix

@Appendix
  @Title { A Complete @Cat Example: @I fak }
  @Tag { complete.Cat }
@Begin
@PP
@TargetForExtract "check/CatFak"
@IgnoreForOutput @Haskell @Begin
import "LangPrelude.prg"
data Thrist :: (* ~> * ~> *) ~> * ~> * ~> * where
  Nil :: Thrist p a a
  Cons :: p a b -> Thrist p b c -> Thrist p a c
 deriving List(l) 
@End @Haskell

We need a type-level function for converting
type arrows into matching configutations of the
top-of-the-stack. This is done by @Haskell {blowUpBy}.
@Haskell {range} on the other hand finds the result type
of a function arrow.
@LD @Haskell @Begin
blowUpBy :: * ~> * ~> *
{blowUpBy (a -> b) s} = (a, {blowUpBy b s})
{blowUpBy Int s} = s
{blowUpBy Bool s} = s

range :: * ~> *
{range (c -> d)} = {range d}
{range Int} = Int
{range Bool} = Bool
@End @Haskell

All types in the type universe that our (simplified) @Cat program can operate on
is witnessed by a value of @Haskell {Tractable}, and @Haskell {sameRep}
states their equality between them.

@LD @Haskell @Begin
data Tractable :: * ~> * where
  IntT :: Tractable Int
  BoolT :: Tractable Bool
  ArrT :: Tractable a -> Tractable b -> Tractable (a -> b)

sameRep :: Tractable a -> Tractable b -> Maybe (Equal a b)
sameRep IntT IntT = Just Eq
sameRep BoolT BoolT = Just Eq
sameRep (ArrT a b) (ArrT c d) = let monad maybeM in do
    Eq <- sameRep a c
    Eq <- sameRep b d
    return Eq
sameRep _ _ = Nothing
@End @Haskell

Now we can introduce the @Haskell {Cat} datatype which fixes the
language primitives and typing rules.

@LD @Haskell @Begin
data Cat :: * ~> * ~> * where
  Push :: a -> Cat opaque (a, opaque)
  Pop :: Cat (a, opaque) opaque
  Dup :: Cat (a, opaque) (a, (a, opaque))
  Prim :: Tractable b -> (a -> b) -> Cat {blowUpBy (a -> b) opaque} ({range b}, opaque)
  Block :: Thrist Cat b c -> Cat opaque (Thrist Cat b c, opaque)
  Fun :: Function b c -> Cat opaque (Thrist Cat b c, opaque)
  Apply :: Cat (Thrist Cat b c, b) c
  If :: Cat (Thrist Cat s t, Thrist Cat s t, Bool, s) t
  Print :: Cat (a, opaque) opaque
  Call :: (IO b -> IO c) -> Cat b c
@End @Haskell

To define the needed primitives that can be used in this appendix
we propose a small set of some abbreviations:

@LD @Haskell @Begin
intint = ArrT IntT IntT
intbool = ArrT IntT BoolT

flip f a b = f b a

minus = Prim intint $ flip (-)
times = Prim intint (*)
equals = Prim intbool (==)
@End @Haskell

We are about to define callable functions. To this end
we need a datatype to evidence the transformations
on the shape of the stack as performed by the function.
It will allow us to compare two functions. Since our
example only contains a single function, we do not
bother naming them. The identification is taken care of
by an atom. @Haskell { Sound }'s constructors cater for
elementary changes in the stack's shape. They can
be contained in a thrist to get a net effect.

@LD @Haskell @Begin
data Sound :: * ~> * ~> * where
  Nop :: Atom opaque -> Sound (Cat () ()) (Cat opaque opaque)
  In :: Tractable new -> Sound (Cat a b) (Cat (new, a) b)
  Out :: Tractable new -> Sound (Cat a b) (Cat a (new, b))

data Function :: * ~> * ~> * where
  Function :: Thrist Sound (Cat () ()) (Cat a b)
              -> Thrist Cat a b
              -> Function a b

-- build the faculty function
fakFunc :: IO (Function (Int, op) (Int, op))
fakFunc = let monad ioM in do
      a <- freshAtom
      let loosen :: Function (Int, op) (Int, op) -> Function (Int, op') (Int, op')
          loosen = unsafeCast
      let fak = [Dup, Push 0, equals,
                   Block [Pop, Push 1]l,
                   Block [Dup, Push 1, minus, Fun $ loosen f, Apply, times]l,
                 If]l
          f = Function [Nop a, In IntT, Out IntT]l fak
      return f

compile :: Thrist Cat a b -> Code (IO a -> IO b)
compile []l = [| id |]

compile [Print; rest]l =
   [| \st -> let monad ioM in do
        (a, st') <- st
        putStr $ show a
        $(compile rest) $ return st' |]

compile [Pop; rest]l =
   [| \st -> let monad ioM in do
        (_, st') <- st
        $(compile rest) $ return st' |]

compile [Dup; rest]l =
   [| \st -> let monad ioM in do
        (st'@(a, _)) <- st
        $(compile rest) $ return (a, st') |]

compile [Push a; rest]l =
   [| \st -> let monad ioM in do
        st' <- st
        $(compile rest) $ return (a, st') |]

compile [Prim tr f; rest]l =
   [| \st -> let monad ioM in do
        st' <- st
        let (a', st'') = deepApply f tr st'
        $(compile rest) $ return (a', st'') |]

compile [Block true, Block false, If; rest]l =
   [| \st -> let monad ioM in do
        (cond, st') <- st
        let st'' = if cond then $(compile true) (return st') else $(compile false) (return st')
        $(compile rest) st'' |]

compile [Call c; rest]l =
   [| \st -> let monad ioM in do
        $(compile rest) $ c st |]

compile [Fun f, Apply; rest]l =
   [| \st -> let monad ioM in do
        $(compile rest') $ f' st |]
  where f' = run $ compileFun f
        rest' = subst f f' rest

deepApply :: (f -> g) -> Tractable g -> (f, {blowUpBy g u}) -> ({range g}, u)
deepApply f (arr@ArrT _ to) (a, st) = deepApply (f a) to st
deepApply f IntT (a, st) = (f a, st)
deepApply f BoolT (a, st) = (f a, st)

compileFun :: Function f t -> Code (IO f -> IO t)
compileFun (f@(Function _ c)) = let compiled = compile $ subst f (mimic run compiled) c in compiled

subst :: Function f t -> (IO f -> IO t) -> Thrist Cat a b -> Thrist Cat a b
subst _ _ []l = []l

subst (f@Function t _) c [(b@Fun (Function t' _)), (a@Apply); rest]l =
    case sameSound t t' of
        Just Eq -> [Call c; subst f c rest]l
        _ -> [b, a; rest]l

subst f c [Block b; rest]l = [Block (subst f c b); subst f c rest]l
subst f c [head; tail]l = [head; subst f c tail]l


sameSound2 :: Equal a a' -> Thrist Sound a b -> Thrist Sound a' b' -> Maybe (Equal b b')
sameSound2 Eq [Nop a; rest]l [Nop a'; rest']l = let monad maybeM in do
    Eq <- same a a'
    Eq <- sameSound2 Eq rest rest'
    return Eq
sameSound2 Eq [In a; rest]l [In a'; rest']l = let monad maybeM in do
    Eq <- sameRep a a'
    Eq <- sameSound2 Eq rest rest'
    return Eq
sameSound2 Eq [Out a; rest]l [Out a'; rest']l = let monad maybeM in do
    Eq <- sameRep a a'
    Eq <- sameSound2 Eq rest rest'
    return Eq
sameSound2 Eq []l []l = Just Eq
sameSound2 _ _ _ = Nothing

sameSound = sameSound2 Eq
@End @Haskell

We can now compute a factorial using

@LD @Haskell @Begin
usecase = let monad ioM in do
    fak <- fakFunc
    let thr = [Push 5, Fun fak, Apply, Print]l
    _ <- (run $ compile thr) (returnIO ())
    return ()
@End @Haskell

usecase @Prompt {
Executing IO action
@LP 120
}

@End @Appendix

@Appendix
  @Title { Parsing @CLang Literals }
  @Tag { parsing.token }
@Begin
@PP
@TargetForExtract "check/ParseC"
@IgnoreForOutput @Haskell @Begin
import "LangPrelude.prg"
data Thrist :: (* ~> * ~> *) ~> * ~> * ~> * where
  Nil :: Thrist p a a
  Cons :: p a b -> Thrist p b c -> Thrist p a c
 deriving List(l) 
@End @Haskell

@LD @Haskell @Begin
data Parse :: * ~> * ~> * where
  Atom :: Char -> Parse Char Char
  Sure :: (a -> b) -> Parse a b
  Try :: (a -> Maybe b) -> Parse a b
  Rep1 :: Parse a b -> Parse [a] ([b], [a])
  Rep :: Parse [a] (b, [a]) -> Parse [a] ([b], [a])
  Group :: [Parse a b] -> Parse [a] ([b], [a])
  Par :: Parse a b -> Parse c d -> Parse (a, c) (b, d)
  Wrap :: Thrist Parse a b -> Parse a b


parse :: Thrist Parse a b -> a -> Maybe b

parse []l a = Just a

parse [Atom c; r]l a = if ord c == ord a then parse r a else Nothing

parse [Sure f; r]l a = parse r (f a)

parse [Try f; r]l a = do { b <- f a; parse r b } where monad maybeM

parse [Rep1 p; r]l as = parse r (parseRep p as) where
      parseRep :: Parse a b -> [a] -> ([b], [a])
      parseRep _ [] = ([], [])
      parseRep p (as@(a:ar)) = case parse [p]l a of
          Nothing -> ([], as)
          Just b -> (b:bs, rest)
             where (bs, rest) = parseRep p ar

parse [Rep p; r]l as = parse r (parseRep [p]l as) where
      parseRep :: Thrist Parse [a] (b, [a]) -> [a] -> ([b], [a])
      parseRep _ [] = ([], [])
      parseRep p as = case parse p as of
                      Nothing -> ([], as)
                      Just (b, as') -> (b:bs, rest)
                          where (bs, rest) = parseRep p as'

parse [Group ps; r]l as = do { bs <- parseGroup ps as; parse r bs } where
      monad maybeM
      parseGroup :: [Parse a b] -> [a] -> Maybe ([b], [a])
      parseGroup [] rest = Just ([], rest) -- overlength input
      parseGroup _ [] = Nothing            -- input too short
      parseGroup (p:ps) (a:as) = do
				 b <- parse [p]l a
				 (bs, rest) <- parseGroup ps as
				 return (b:bs, rest)

parse [Wrap thr; r]l a = do { a' <- parse thr a; parse r a' } where monad maybeM

@End @Haskell

@End @Appendix

@Appendix
  @Title { Adapting Haskell's @Haskell {Arrow} Class }
  @Tag { arrow.adapter }
@Begin
@PP
We show how the two elementary @Haskell {Arrow} operations
(viz. @Haskell {arr} and @Haskell {>>>}) are directly related
to the two @Haskell {Thrist} data constructors. This example is
in Haskell as @Omega does not support type classes.

@LD @Haskell @Begin
module Embeddings where
import Prelude
import Control.Arrow
import Char

data Thrist :: (* -> * -> *) -> * -> * -> * where
  Nil :: Thrist p a a
  Cons :: p a b -> Thrist p b c -> Thrist p a c

data Arrow' :: (* -> * -> *) -> * -> * -> * where
  Arr :: Arrow a => a b c -> Arrow' a b c
  First :: Arrow a => Arrow' a b c -> Arrow' a (b, d) (c, d)

recover :: Arrow a => Thrist (Arrow' a) b c -> a b c
recover Nil = arr id
recover (Cons (Arr f) r) = f >>> recover r
recover (Cons (First a) r) = first (recover $ Cons a Nil) >>> recover r

@End @Haskell

@End @Appendix
